# Comentario "Combining Predictions for Accurate Recommender Systems"

Este texto analiza las mejoras que se pueden lograr al implementar "blending", es decir, la combinación de las predicciones de varios algoritmos de recomendación para obtener una predicción final. Esta predicción final puede mejorar en distintos grados la calidad de la predicción, dependiendo de su sofisticación.

Parece ser una estrategia bastante lógica para reducir el error de las recomendaciones, sin embargo, con mi poca experiencia he visto bastante que comparan algoritmos de recomendación unos con otros para elegir el mejor, pero la realidad sugiere que elegir varios de la lista solo mejoraría el performance del proceso. Probablemente la razón de ser de estas discusiones es que incorporar varios implica un costo mayor, con el que la mejora marginal puede resultar poco llamativa. Aún así, si se habla solamente de performance, como para competencias de estilo Netflix Prize, queda claro que el "blending" es una estrategia efectiva.

El problema que surge con el blending es el de elegir las combinaciones correctas que se complementen y optimicen el proceso, tanto en términos de costo como de efectividad. Además, puede ocurrir que el proceso que minimiza el error no siempre es el más conveniente, debido a los distintos costos que puede significar. Una recomendación final que hacen los autores del texto es que, para efectos prácticos, el "blending" sea implementado por una red neuronal, debido a su alta velocidad de predicción. También recomiendan implementar "bagging" o "bootstrap aggregating", un método que subdivide conjuntos usando muestreo uniforme para agregar estabilidad a algunos procedimientos, como es el caso de las redes neuronales. Existen otros casos, como el de "K-nearest-neighbors", en el que "bagging" puede producir efectos negativos o degradantes a largo plazo (https://es.wikipedia.org/wiki/Agregaci%C3%B3n_de_bootstrap#Descripci%C3%B3n_de_la_t%C3%A9cnica).

